{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Visualizations\n",
    "##### Data visualizations of print books in the University of Edinburgh's library\n",
    "\n",
    "* **Funding:** Edinburgh Futures Institute (EFI)\n",
    "* **Data Source:** Library and University Collections (L&UC), OCLC MARC Data for Print Books\n",
    "* **Project Dates:** 17 June 2019 - 27 July 2019\n",
    "* **Author:** Lucy Havens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: to run this notebook please launch in a terminal window with the following command (the default date rate limit is too small to run the notebook properly): *jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000000*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df0 = pd.read_csv(\"/afs/inf.ed.ac.uk/user/s15/s1545703/Downloads/LibViz_DICE/Data/MARC_data.csv\")\n",
    "\n",
    "# df_tem = pd.read_csv('Data/VizData_ToClean/temporal_MARC_data.csv')   #(\"/afs/inf.ed.ac.uk/user/s15/s1545703/Downloads/LibViz_DICE/Data/temporal_MARC_data.csv\")\n",
    "df_geo = pd.read_csv('Data/VizData_ToClean/geographic_MARC_data.csv')   #(\"/afs/inf.ed.ac.uk/user/s15/s1545703/Downloads/LibViz_DICE/Data/geographic_MARC_data.csv\")\n",
    "# df_top = pd.read_csv('Data/VizData_ToClean/topical_MARC_data.csv')   #(\"/afs/inf.ed.ac.uk/user/s15/s1545703/Downloads/LibViz_DICE/Data/topical_MARC_data.csv\")\n",
    "\n",
    "# df = pd.concat(map(pd.read_csv, glob.glob('Data/BatchToClean/*.csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()\n",
    "# df_geo.head()\n",
    "# df_tem.head()\n",
    "# df_top.head()\n",
    "# df_geo.columns\n",
    "df_publ_place = pd.DataFrame()\n",
    "df_publ_place['publ_place'] = df_geo['publ_place']\n",
    "df_publ_place['publ_place1'] = df_geo['publ_place1']\n",
    "df_publ_place.to_csv('Data/VizData_ToClean/publication_place_MARC_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'isbn', 'isbn1', 'loc_call_no', 'subject_cat_code',\n",
       "       'dewey_no', 'personal_name', 'relator', 'uniform_title',\n",
       "       'uniform_title1', 'title', 'title_cont', 'stat_of_resp',\n",
       "       'content_type_term', 'content_type_code', 'titles_words_assoc_w_name',\n",
       "       'title1', 'general_subdivision', 'form_subdivision',\n",
       "       'general_subdivision1', 'topic_or_geo', 'general_subdivision2',\n",
       "       'general_subdivision3', 'genre_form_focus', 'genre_form_focus1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1366522\n",
      "Columns: 19\n",
      "\n",
      "Rows: 1366522\n",
      "Columns: 19\n",
      "\n",
      "Rows: 1366522\n",
      "Columns: 25\n"
     ]
    }
   ],
   "source": [
    "# shape0 = df_0.shape\n",
    "# print(\"Rows:\", shape0[0])\n",
    "# print(\"Columns:\", shape0[1])\n",
    "\n",
    "df_geo_shape = df_geo.shape\n",
    "print(\"Rows:\", df_geo_shape[0])\n",
    "print(\"Columns:\", df_geo_shape[1])\n",
    "print()\n",
    "df_tem_shape = df_tem.shape\n",
    "print(\"Rows:\", df_tem_shape[0])\n",
    "print(\"Columns:\", df_tem_shape[1])\n",
    "print()\n",
    "df_top_shape = df_top.shape\n",
    "print(\"Rows:\", df_top_shape[0])\n",
    "print(\"Columns:\", df_top_shape[1])\n",
    "\n",
    "assert df_geo_shape[0] == df_tem_shape[0]\n",
    "assert df_top_shape[0] == df_tem_shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove empty columns (columns in which every row is NaN, meaning the values are missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Maximum number of empty values = total number of rows in the dataframe\n",
    "# total_rows = df0.shape[0]\n",
    "# col_list0 = list(df0.columns)\n",
    "# cols_to_drop = [] # create a list of columns to drop\n",
    "# for col0 in col_list0:\n",
    "#     if df0[col0].isnull().sum() == total_rows:\n",
    "#         cols_to_drop += [col0]\n",
    "\n",
    "# print(\"Empty Columns:\", cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df0.drop(['Unnamed: 0'], axis=1, inplace=True) # columns are axis 1, rows are axis 0\n",
    "# df0.head()\n",
    "\n",
    "df_geo.drop(['Unnamed: 0'], axis=1, inplace=True) # columns are axis 1, rows are axis 0\n",
    "# df_geo.head()\n",
    "\n",
    "# df_tem.drop(['Unnamed: 0'], axis=1, inplace=True) # columns are axis 1, rows are axis 0\n",
    "# df_tem.head()\n",
    "\n",
    "df_top.drop(['Unnamed: 0'], axis=1, inplace=True) # columns are axis 1, rows are axis 0\n",
    "# df_top.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find records for print books (identified as \"text\" (\"txt\") in the MARC data) and remove the rest of the records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69274\n"
     ]
    }
   ],
   "source": [
    "# List of acceptable values identifying print books (modify as needed for different datasets)\n",
    "print_book_values = ['text','txt','tetx', 'testo','tekst', 'texto']\n",
    "\n",
    "df_formats = pd.DataFrame()\n",
    "df_formats[\"content_type_term\"] = df_top[\"content_type_term\"]\n",
    "df_formats[\"content_type_code\"] = df_top[\"content_type_code\"]\n",
    "\n",
    "terms = list(df_formats.iloc[:, 0].unique())\n",
    "codes = list(df_formats.iloc[:, 1].unique())\n",
    "\n",
    "unacceptable_terms = []\n",
    "for term in terms:\n",
    "    term = term.lower()\n",
    "    term = term.replace(' ','')\n",
    "    acceptable = False\n",
    "    for val in print_book_values:\n",
    "        if val in term:\n",
    "            acceptable = True\n",
    "    if not acceptable:\n",
    "        unacceptable_terms += [term]\n",
    "\n",
    "unacceptable_codes = []\n",
    "for code in codes:\n",
    "    code = code.lower()\n",
    "    code = code.replace(' ','')\n",
    "    acceptable = False\n",
    "    for val in print_book_values:\n",
    "        if val in code:\n",
    "            acceptable = True\n",
    "    if not acceptable:\n",
    "        unacceptable_codes += [code]\n",
    "\n",
    "index_list = []\n",
    "for t in unacceptable_terms:\n",
    "    rowsToRemove = df_formats[df_formats.iloc[:,0] == t]\n",
    "    indecesToRemove = rowsToRemove.index\n",
    "    if len(indecesToRemove) > 0:\n",
    "        for i in indecesToRemove:\n",
    "            index_list += [i]\n",
    "for c in unacceptable_codes:\n",
    "    rowsToRemove = df_formats[df_formats.iloc[:,1] == c]\n",
    "    indecesToRemove = rowsToRemove.index\n",
    "    if len(indecesToRemove) > 0:\n",
    "        for i in indecesToRemove:\n",
    "            index_list += [i]\n",
    "            \n",
    "print(len(index_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on Boolean Operations\n",
    "\n",
    "We can combine conditions through logical **boolean operations**. Boolean operations are logical constructs that work through the following **boolean operators**: \n",
    "\n",
    "1. **AND (`&`)**: selects a row if **all** conditions joined by an `&` sign are true:\n",
    "    *  e.g. `df.loc[(df['1960'] > 1000) & (df['1960'] < 3000)]` returs all countries with values between 1000 **and** 3000. \n",
    "    \n",
    "* **OR ('|')**: selects a row if **at least one** of the conditions joined by a `|` (say 'pipe') sign are true:\n",
    "    * e.g. `df.loc[(df['1960'] < 1000) | (df['1960'] > 3000])` returs all countries with values smaller than 1000 **or** with values larger than 3000. \n",
    "    \n",
    "* **NOT(~)**: selects a row if a **condition is not met**. the `~` charater (say 'tilde') has to stand _before_ the condition: \n",
    "    *  e.g. `df.loc[~(df['1960'] < 1000)]` returs all countries with values not lower than 1000 (i.e. rows with values higher than 1000, including 1000.) \n",
    "\n",
    "You can combine these boolean operations in many ways using parentheses, as in the following example, which returns all countries with values between 1000 and 3000, or countries with values exactly 10000 in 1960.\n",
    "\n",
    "`df.loc[((df['1960'] > 1000) & (countryData['1960'] < 3000)) | (countryData['1960'] == 10000)]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To make sure the acceptable_terms_code list reflects the dataset:\n",
    "    \n",
    "# print(df_top['content_type_code'].value_counts())\n",
    "# print(df_top['content_type_term'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df0.drop(index_list, inplace=True)\n",
    "# df_tem.drop(index_list, inplace=True)\n",
    "df_geo.drop(index_list, inplace=True)\n",
    "df_top.drop(index_list, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All dataframes should include the same print books (meaning they have the same number of rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geographic MARC data\n",
      "Rows: 1297311\n",
      "Columns: 18\n",
      "\n",
      "Topical MARC data\n",
      "Rows: 1297311\n",
      "Columns: 24\n"
     ]
    }
   ],
   "source": [
    "# print('All MARC data')\n",
    "# print(\"Rows:\", df0.shape[0])\n",
    "# print(\"Columns:\", df0.shape[1])\n",
    "# print()\n",
    "# print('Temporal MARC data')\n",
    "# print(\"Rows:\", df_tem.shape[0])\n",
    "# print(\"Columns:\", df_tem.shape[1])\n",
    "# print()\n",
    "print('Geographic MARC data')\n",
    "print(\"Rows:\", df_geo.shape[0])\n",
    "print(\"Columns:\", df_geo.shape[1])\n",
    "print()\n",
    "print('Topical MARC data')\n",
    "print(\"Rows:\", df_top.shape[0])\n",
    "print(\"Columns:\", df_top.shape[1])\n",
    "\n",
    "# assert df_top.shape[0] == df_tem.shape[0]\n",
    "# assert df_geo.shape[0] == df_top.shape[0]\n",
    "# assert df_tem.shape[0] == df0.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cleaning\n",
    "\n",
    "Clean identification data fields (listed in italics)\n",
    "\n",
    "1. Consolidate repetitive columns\n",
    "2. Replace missing field values with an empty string or the digit 0 (depending on column's data type)\n",
    "2. Reconcile different field values from columns representing the same data point (i.e. *title* and *title1*)\n",
    "\n",
    "*isbn\n",
    "isbn1\n",
    "personal_name\n",
    "uniform_title\n",
    "real_world_obj_URI\n",
    "uniform_title1\n",
    "real_world_obj_URI1\n",
    "title\n",
    "title_cont\n",
    "stat_of_resp\n",
    "physical_desc\n",
    "content_type_term\n",
    "content_type_code\n",
    "personal_name1\n",
    "title1\n",
    "uniform_title1\n",
    "real_world_obj_URI2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def consolidateColumns(col0, col1, df):  # pass in two columns to consolidate and the dataframe of those columns\n",
    "    clean_values = []\n",
    "\n",
    "    for index,row in df.iterrows():\n",
    "        value0 = str(row[col0]).lower()\n",
    "        value1 = str(row[col1]).lower()\n",
    "        # if there is a value...\n",
    "        if \"Unknown\" not in value0:\n",
    "            value0_list = value0.split(';')\n",
    "            if \"Unknown\" not in value1:\n",
    "                value1_list = value1.split(';')\n",
    "                for value1 in value1_list:\n",
    "                    if value1 not in value0_list:\n",
    "                        value0_list += [value1]\n",
    "\n",
    "            clean_values += [value0_list]\n",
    "\n",
    "        # if one value is missing...\n",
    "        else:\n",
    "            if \"Unknown\" not in value1:\n",
    "                value1_list = value1.split(';')\n",
    "                clean_values += [value1_list]\n",
    "        # if both values are missing...\n",
    "            else:\n",
    "                clean_values += [[\"\"]]\n",
    "\n",
    "    return clean_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ISBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown                       829361\n",
      "\\\\$cNo price                     318\n",
      "9787106023560                     98\n",
      "7106023566 (booklet : set)        96\n",
      "7805691797                        90\n",
      "7805699941 (set)                  71\n",
      "7805695326 (set) :                58\n",
      "\\\\$cRMBY1.20                      36\n",
      "\\\\$cRMBY1.50                      35\n",
      "\\\\$cRMBY1.40                      33\n",
      "7805695326 (set)                  32\n",
      "9571507695 (set)                  31\n",
      "\\\\$cRMBY1.10                      27\n",
      "\\\\$cRMBY1.00                      27\n",
      "\\\\$cRMBY1.15                      25\n",
      "\\\\$cRMBY1.25                      24\n",
      "2503360009                        24\n",
      "\\\\$cNT{dollar}120.00              23\n",
      "\\\\$cRMBY1.30                      21\n",
      "\\\\$cNo price (pbk)                21\n",
      "9575432525                        21\n",
      "\\\\$cRMBY1.05                      21\n",
      "\\\\$c(pbk)                         20\n",
      "\\\\$c(pbk.)                        20\n",
      "\\\\$cRMBY1.80                      20\n",
      "7805697418 (set)                  20\n",
      "\\\\$cRMBY1.35                      19\n",
      "\\\\$cRMBY1.60                      19\n",
      "\\\\$cRMBY1.65                      18\n",
      "1560811900                        18\n",
      "                               ...  \n",
      "9781853461149 (pbk)                1\n",
      "0582210615                         1\n",
      "0948374020                         1\n",
      "0752425528                         1\n",
      "9780895792433                      1\n",
      "9780198238089                      1\n",
      "0912776838                         1\n",
      "033520385X                         1\n",
      "9781853461323                      1\n",
      "9780739172766 (alk. paper)         1\n",
      "8870170357                         1\n",
      "0201122219                         1\n",
      "0810936690                         1\n",
      "9789629961183 (pbk.)               1\n",
      "0801867681 (pbk.)                  1\n",
      "0521852617 (hardback)              1\n",
      "0717108643                         1\n",
      "0946897549                         1\n",
      "025202883X                         1\n",
      "0788504266                         1\n",
      "0444872957                         1\n",
      "0700510168                         1\n",
      "9004141545                         1\n",
      "8772889128 (pbk.)                  1\n",
      "2742705317                         1\n",
      "0500820031                         1\n",
      "3791307975 :                       1\n",
      "9780199262861                      1\n",
      "0470673591                         1\n",
      "8716142721                         1\n",
      "Name: isbn, Length: 530803, dtype: int64\n",
      "Unknown                        829361\n",
      "(pbk)                           22679\n",
      "(pbk.)                           4930\n",
      "(alk. paper)                     1728\n",
      "(U.S.)                           1400\n",
      "No price                         1032\n",
      "(acid-free paper)                 967\n",
      "(set)                             916\n",
      "(v.2)                             804\n",
      "(pbk. : alk. paper)               498\n",
      "no price                          479\n",
      "(New York)                        391\n",
      "(v.3)                             260\n",
      "(US)                              250\n",
      "(Berlin)                          235\n",
      "(U.S. : alk. paper)               212\n",
      "(v. 2)                            204\n",
      "(v.1)                             198\n",
      "£9.99                             180\n",
      "(v. 1)                            180\n",
      "(series)                          147\n",
      "£25.00                            147\n",
      "(acid-free, recycled paper)       128\n",
      "£14.99                            126\n",
      "(microfiche)                      126\n",
      "£8.99                             126\n",
      "(pbk : acid-free paper)           123\n",
      "(hard)                            123\n",
      "(lib. bdg.)                       120\n",
      "(pbk : alk. paper)                119\n",
      "                                ...  \n",
      "\\\\$a186156144X                      1\n",
      "\\\\$a9780416127522$qhardback         1\n",
      "\\\\$a0435292188                      1\n",
      "\\\\$a0774805323                      1\n",
      "\\\\$a0255367015$qpaperback           1\n",
      "\\\\$a0750216999                      1\n",
      "\\\\$a849793783X                      1\n",
      "\\\\$a3476004368                      1\n",
      "\\\\$a9781841583167 (hbk.)            1\n",
      "\\\\$a0820416746                      1\n",
      "\\\\$a3772813402$qBand 4              1\n",
      "\\\\$a2207243907                      1\n",
      "\\\\$a2907293249                      1\n",
      "\\\\$a0406351694                      1\n",
      "\\\\$a0886451906                      1\n",
      "\\\\$a0486281493                      1\n",
      "\\\\$a144410988X                      1\n",
      "\\\\$a9788821008382                   1\n",
      "\\\\$a9780140309058$q(pbk.)           1\n",
      "\\\\$a0716501597 (v.3)                1\n",
      "\\\\$a3533024547                      1\n",
      "\\\\$a0872204006 (pbk)                1\n",
      "\\\\$a9781898331445                   1\n",
      "\\\\$a9042007397                      1\n",
      "\\\\$a9783421032843                   1\n",
      "\\\\$a8430635033                      1\n",
      "\\\\$a0240449428                      1\n",
      "\\\\$a881704492X$qhardback            1\n",
      "\\\\$a1874579571                      1\n",
      "\\\\$a9781841717890                   1\n",
      "Name: isbn1, Length: 479812, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print(isbns.isnull().sum())\n",
    "# print(isbn1s.isnull().sum())\n",
    "# print(df0['isbn'].value_counts())\n",
    "# print(df0['isbn1'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# isbns = (df0['isbn'])\n",
    "# isbn1s = (df0['isbn1'])\n",
    "\n",
    "isbns = (df_tem['isbn'])\n",
    "isbn1s = (df_tem['isbn1'])\n",
    "\n",
    "# isbns = (df_geo['isbn'])\n",
    "# isbn1s = (df_geo['isbn1'])\n",
    "\n",
    "# isbns = (df_top['isbn'])\n",
    "# isbn1s = (df_top['isbn1'])\n",
    "\n",
    "isbns_list = list(isbns)\n",
    "isbn1s_list = list(isbn1s)\n",
    "assert len(isbns_list) == len(isbn1s_list) # confirm isbns and isbn1s are the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_isbns = consolidateColumns('isbn','isbn1',df_tem)\n",
    "assert len(clean_isbns) == len(list(df_tem[\"isbn\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validISBNs(clean_values_list):\n",
    "    # remove words and abbreviations from list of isbns\n",
    "    cleaner_isbns = []\n",
    "    for isbn_list in clean_isbns:\n",
    "        new_list = []\n",
    "        for isbn in isbn_list:\n",
    "            test0 = re.findall(\"\\d+[\\D?]$\",isbn)\n",
    "            test1 = re.findall(\"\\d+\",isbn)\n",
    "            if (len(test0) > 0):\n",
    "                new_list += test0\n",
    "            elif (len(test1) > 0):\n",
    "                new_list += test1\n",
    "            else:\n",
    "                new_list += \"\"\n",
    "\n",
    "        cleaner_isbns += [new_list]\n",
    "\n",
    "    # Each isbn value should be at least 10 characters in length\n",
    "    for isbn_list in cleaner_isbns:\n",
    "        for isbn in isbn_list:\n",
    "            if (len(isbn) < 10):\n",
    "                isbn_list.remove(isbn)\n",
    "    \n",
    "    return cleaner_isbns\n",
    "\n",
    "cleaner_isbns = validISBNs(clean_isbns)\n",
    "assert len(cleaner_isbns) == len(list(df_tem[\"isbn\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1139301</th>\n",
       "      <td>[3100381343]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139302</th>\n",
       "      <td>[091280405x]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139303</th>\n",
       "      <td>[2222027888, 2222027888]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139304</th>\n",
       "      <td>[0404617220, 0404617220]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139305</th>\n",
       "      <td>[0824090470]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             isbn\n",
       "1139301              [3100381343]\n",
       "1139302              [091280405x]\n",
       "1139303  [2222027888, 2222027888]\n",
       "1139304  [0404617220, 0404617220]\n",
       "1139305              [0824090470]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df0_clean = pd.DataFrame()\n",
    "# df0_clean[\"isbn\"] = cleaner_isbns\n",
    "# df0_clean.tail()\n",
    "\n",
    "df_tem_clean = pd.DataFrame()\n",
    "df_tem_clean[\"isbn\"] = cleaner_isbns\n",
    "df_tem_clean.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Author\n",
    "Time permitting: see if author names can by identified in statements of responsibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424279\n"
     ]
    }
   ],
   "source": [
    "# personal_name, stat_of_resp, personal_name1\n",
    "\n",
    "personal_names = list(df_tem['personal_name'])\n",
    "statements_of_responsibility = list(df_tem['stat_of_resp'])\n",
    "unmatched_indeces = []\n",
    "maxI = len(personal_names)\n",
    "i = 0\n",
    "while i < maxI:\n",
    "    names = str(personal_names[i])\n",
    "    alpha_list = re.findall('\\w+',names)\n",
    "    statement = str(statements_of_responsibility[i])\n",
    "    is_in = False\n",
    "    for name in alpha_list: \n",
    "        if name in statement:\n",
    "            is_in = True\n",
    "    if not is_in:\n",
    "        unmatched_indeces += [i]\n",
    "    i += 1\n",
    "print(len(unmatched_indeces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the code below when working with smaller, test datasets\n",
    "# for i in unmatched_indeces:\n",
    "#     print(personal_names[i], \"|\", statements_of_responsibility[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new_names = []\n",
    "# for item in personal_names:\n",
    "#     name = str(item)\n",
    "#     if name == 'Unknown':\n",
    "#         new_names += ['Unknown']\n",
    "#     else:\n",
    "#         m = n.strip(',')\n",
    "#         new_names += [m]\n",
    "\n",
    "# assert len(new_names) == len(personal_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1139301</th>\n",
       "      <td>[3100381343]</td>\n",
       "      <td>Kafka, Franz,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139302</th>\n",
       "      <td>[091280405x]</td>\n",
       "      <td>Mezzatesta, Michael P.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139303</th>\n",
       "      <td>[2222027888, 2222027888]</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139304</th>\n",
       "      <td>[0404617220, 0404617220]</td>\n",
       "      <td>Land, Stephen K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139305</th>\n",
       "      <td>[0824090470]</td>\n",
       "      <td>Leistritz, Larry,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             isbn                  author\n",
       "1139301              [3100381343]           Kafka, Franz,\n",
       "1139302              [091280405x]  Mezzatesta, Michael P.\n",
       "1139303  [2222027888, 2222027888]                 Unknown\n",
       "1139304  [0404617220, 0404617220]        Land, Stephen K.\n",
       "1139305              [0824090470]       Leistritz, Larry,"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tem_clean[\"author\"] = list(df_tem[\"personal_name\"])\n",
    "df_tem_clean.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Publication Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396\n",
      "6\n",
      "396\n",
      "397\n",
      "396\n",
      "337\n",
      "368\n",
      "378\n",
      "397\n"
     ]
    }
   ],
   "source": [
    "# print(df0['date_of_work'].isnull().sum())\n",
    "# print(df0['publ_date'].isnull().sum())\n",
    "# print(df0['publ_date1'].isnull().sum())\n",
    "# print(df0['time_period_of_content'].isnull().sum())\n",
    "# print(df0['geo_subdivision'].isnull().sum())\n",
    "# print(df0['dates_assoc_w_name'].isnull().sum())\n",
    "# print(df0['chrono_subdivision'].isnull().sum())\n",
    "# print(df0['chrono_subdivision1'].isnull().sum())\n",
    "# print(df0['chrono_subdivision2'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use 'publ_date' column (as it has the fewest empty values in the test dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# INPUT: string date range (contains '-')\n",
    "# OUTPUT: list with the minimum and maximum dates as 4-digit strings\n",
    "# Example 1: '1928-29' --> [1928, 1929]\n",
    "# Example 2: '1830-5'  --> [1830, 1835]\n",
    "def dateRangeToList(date_range):\n",
    "    new_dates = []\n",
    "    date_list = date_range.split('-')\n",
    "    for d in date_list:\n",
    "        d = d.strip('.')\n",
    "        d = d.strip(',')\n",
    "        if len(d) == 2:\n",
    "            first_two = date_list[0][0] + date_list[0][1]\n",
    "            new_d = first_two + d\n",
    "            new_dates += [int(new_d)]\n",
    "        elif len(d) == 1:\n",
    "            first_three = date_list[0][0] + date_list[0][1] + date_list[0][2]\n",
    "            new_d = first_three + d\n",
    "            new_dates += [int(new_d)]\n",
    "        elif len(d) == 4:\n",
    "            new_dates += [int(d)]\n",
    "        else:\n",
    "            print(d)\n",
    "\n",
    "    return new_dates\n",
    "\n",
    "# From: www.oreilly.com/library/view/python-cookbook/0596001673/ch03s24.html\n",
    "def int_to_roman(input):\n",
    "    if not isinstance(input, type(1)):\n",
    "        return \"Expected type integer\"\n",
    "    if not 0 < input < 4000:\n",
    "        return \"Argument must be between 1 and 3999\"\n",
    "    ints = (1000, 900,  500, 400, 100,  90, 50,  40, 10,  9,   5,  4,   1)\n",
    "    nums = ('M',  'CM', 'D', 'CD','C', 'XC','L','XL','X','IX','V','IV','I')\n",
    "    result = []\n",
    "    for i in range(len(ints)):\n",
    "        count = int(input / ints[i])\n",
    "        result.append(nums[i] * count)\n",
    "        input -= ints[i] * count\n",
    "    return ''.join(result)\n",
    "\n",
    "# INPUT: string of capital letters (roman numerals)\n",
    "# OUTPUT: 4-digit string (year)\n",
    "def romanToDigits(roman_numerals):\n",
    "    # Remove any punctuation and spaces from the inputted string\n",
    "    no_spaces = roman_numerals.replace(\" \",\"\")\n",
    "    input = no_spaces.replace(\".\",\"\")\n",
    "    \n",
    "    # From: www.oreilly.com/library/view/python-cookbook/0596001673/ch03s24.html\n",
    "    if not isinstance(input, type(\"\")):\n",
    "        return \"Expected string\"\n",
    "    input = input.upper(  )\n",
    "    nums = {'M':1000, 'D':500, 'C':100, 'L':50, 'X':10, 'V':5, 'I':1}\n",
    "    sum = 0\n",
    "    for i in range(len(input)):\n",
    "        try:\n",
    "            value = nums[input[i]]\n",
    "            # If the next place holds a larger number, this value is negative\n",
    "            if i+1 < len(input) and nums[input[i+1]] > value:\n",
    "                sum -= value\n",
    "            else: sum += value\n",
    "        except KeyError:\n",
    "            return \"0\"\n",
    "    # easiest test for validity...\n",
    "    if int_to_roman(sum) == input:\n",
    "        return sum\n",
    "    else:\n",
    "        return \"0\"\n",
    "    \n",
    "\n",
    "# INPUT: century string (matches regex pattern '\\d{2}\\w{2}')\n",
    "# Examples: '20th century', '21st'\n",
    "# OUTPUT: list of minimum and maximum years as 4-digit strings\n",
    "# Examples: ['1900','1999'], ['1900','2099']\n",
    "def centuryToYears(c):\n",
    "    digits = re.findall('\\d{2}',c)\n",
    "    years = []\n",
    "    for century in digits:\n",
    "        four_digits = int(century + '00')\n",
    "        min_year = four_digits - 100\n",
    "        max_year = four_digits - 1\n",
    "    \n",
    "    return [int(min_year),int(max_year)]\n",
    "    \n",
    "\n",
    "# INPUT: date string\n",
    "# OUTPUT: 4 digit year as integer (earliest if multiple) UNLESS no date provided, in which case 0 is returned\n",
    "def cleanDate(date):\n",
    "    # If no date is provided...\n",
    "    if (str(date) == 'Unknown'):\n",
    "        return 0\n",
    "    else:\n",
    "        # If a year or range of years is provided...\n",
    "        date_range = re.findall('\\d{4}', date)\n",
    "        if len(date_range) == 1:\n",
    "            return int(date_range[0])\n",
    "        elif len(date_range) > 1:\n",
    "            # Turn date strings to integers\n",
    "            min_date = int(date_range[0])\n",
    "            for r in date_range:\n",
    "                r = int(r)\n",
    "                if r < min_date:\n",
    "                    min_date = r\n",
    "            return min_date\n",
    "\n",
    "        # When len(date_range) == 0...\n",
    "        else: \n",
    "            centuries = re.findall('\\d{2}\\w{2}', date)\n",
    "            # If a century is provided, return the first year of that century\n",
    "            if len(centuries) > 0:\n",
    "                for c in centuries:\n",
    "                    year_list = centuryToYears(c)\n",
    "                    return min(year_list)\n",
    "\n",
    "            # When len(centuries) == 0...\n",
    "            else:\n",
    "                # If roman numerals are provided, return the corresponding 4-digit year\n",
    "                return romanToDigits(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "publ_dates = list(df_tem['publ_date'])\n",
    "new_publ_dates = []\n",
    "for d in publ_dates:\n",
    "    new_d = cleanDate(d)\n",
    "    if int(new_d) > 2019:  # If dates are in the future they must be a typo in the catalog\n",
    "        new_d = 0\n",
    "    new_publ_dates += [int(new_d)]\n",
    "\n",
    "assert len(publ_dates) == len(new_publ_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 1828. | 1828. | 1828\n",
      "1 : 1817. | 1817. | 1817\n",
      "2 : 2007. | 2007. | 2007\n",
      "3 : 2008. | 2008. | 2008\n",
      "4 : 2007. | 2007. | 2007\n",
      "5 : 2008. | 2008. | 2008\n",
      "6 : 1838-1839. | 1838-1839. | 1838\n",
      "7 : MDCCCXVII [1817] | MDCCCXVII [1817] | 1817\n",
      "8 : 1878. | 1878. | 1878\n",
      "9 : [2003], ©2003. | [2003], ©2003. | 2003\n",
      "10 : [2004], ©2004. | [2004], ©2004. | 2004\n",
      "11 : MDCCCXVII [1817] | MDCCCXVII [1817] | 1817\n",
      "12 : 1967. | 1967. | 1967\n",
      "13 : MDCCCXVII [1817] | MDCCCXVII [1817] | 1817\n",
      "14 : MDCCCXVII [1817] | MDCCCXVII [1817] | 1817\n",
      "15 : 1986. | 1986. | 1986\n",
      "16 : 1967. | 1967. | 1967\n",
      "17 : 2008. | 2008. | 2008\n",
      "18 : 1986. | 1986. | 1986\n",
      "19 : MDCCCXVII [1817] | MDCCCXVII [1817] | 1817\n"
     ]
    }
   ],
   "source": [
    "# Manual check\n",
    "maxI = 20\n",
    "i = 0\n",
    "while i < maxI:\n",
    "    print(i, \":\", df_tem.iloc[i].publ_date, \"|\", publ_dates[i], \"|\", new_publ_dates[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows to fix: 0 ( 0.0 %)\n"
     ]
    }
   ],
   "source": [
    "# manual check\n",
    "i = 0\n",
    "maxI = len(new_publ_dates)\n",
    "bad_indeces = []\n",
    "while i < maxI:\n",
    "    if (new_publ_dates[i] == \"Unknown\") or (int(new_publ_dates[i]) > 2019):\n",
    "        bad_indeces += [i]\n",
    "    \n",
    "    i += 1\n",
    "print(\"Rows to fix:\", len(bad_indeces), \"(\",(len(bad_indeces)/len(new_publ_dates))*100,\"%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publ_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>19679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>19418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>19152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>19059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      publ_date\n",
       "0        123378\n",
       "1996      19679\n",
       "1997      19418\n",
       "1995      19152\n",
       "1998      19059"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_tem_clean[\"publication_date\"] = new_publ_dates\n",
    "# df_tem_clean.tail()\n",
    "# new_df_tem = pd.DataFrame()\n",
    "# new_df_tem['publ_date'] = new_publ_dates\n",
    "publ_counts = new_df_tem['publ_date'].value_counts()\n",
    "# publ_counts.sort\n",
    "df_pub = pd.DataFrame(publ_counts)\n",
    "df_pub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pub.to_csv('Data/VizData/print_book_yearly_publ_totals.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Title\n",
    "Time permitting: clean!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>author</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>Apollonius,</td>\n",
       "      <td>1828</td>\n",
       "      <td>Apollonii Rhodii Argonautica ::Ad fidem libror...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[9781403976277, 9781403976277]</td>\n",
       "      <td>Ebenstein, Alan O.</td>\n",
       "      <td>2007</td>\n",
       "      <td>Milton Friedman :a biography /</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[9780230007895, 9780230007895]</td>\n",
       "      <td>Szenberg, Michael.</td>\n",
       "      <td>2008</td>\n",
       "      <td>Franco Modigliani :a mind that never rests /</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1403996237, 1403996237]</td>\n",
       "      <td>Davidson, Paul,</td>\n",
       "      <td>2007</td>\n",
       "      <td>John Maynard Keynes /10$aJohn Maynard Keynes /...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1842143050, 1842143050]</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2008</td>\n",
       "      <td>Atlas of contraception /00$aAtlas of contracep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             isbn              author publication_date  \\\n",
       "0                              []         Apollonius,             1828   \n",
       "1  [9781403976277, 9781403976277]  Ebenstein, Alan O.             2007   \n",
       "2  [9780230007895, 9780230007895]  Szenberg, Michael.             2008   \n",
       "3        [1403996237, 1403996237]     Davidson, Paul,             2007   \n",
       "4        [1842143050, 1842143050]             Unknown             2008   \n",
       "\n",
       "                                               title  \n",
       "0  Apollonii Rhodii Argonautica ::Ad fidem libror...  \n",
       "1                     Milton Friedman :a biography /  \n",
       "2       Franco Modigliani :a mind that never rests /  \n",
       "3  John Maynard Keynes /10$aJohn Maynard Keynes /...  \n",
       "4  Atlas of contraception /00$aAtlas of contracep...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INPUT: a dataframe and two MARC fields (dataframe columns) with values of type string\n",
    "# OUTPUT: a list of strings, where each string is a value from col2 appended to a value from col1 in the corresponding row\n",
    "def combineColValues(df,col1,col2):\n",
    "    titles = list(df[col1])\n",
    "    titles_cont = list(df[col2])\n",
    "    full_title_list = []\n",
    "    i = 0\n",
    "    maxI = len(titles)\n",
    "    while i < maxI:\n",
    "        t1 = titles[i]\n",
    "        t2 = titles_cont[i]\n",
    "        if t2 != 'Unknown':\n",
    "            new_title = t1 + t2\n",
    "\n",
    "        else:\n",
    "            new_title = t1\n",
    "        \n",
    "        new_title.strip('/')\n",
    "        new_title.strip()\n",
    "        full_title_list.append(new_title)\n",
    "            \n",
    "        i += 1\n",
    "        \n",
    "    return full_title_list\n",
    "    \n",
    "full_titles = combineColValues(df_tem,'title','title_cont')\n",
    "\n",
    "df_tem_clean[\"title\"] = full_titles\n",
    "df_tem_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export a CSV file of the number of books published in each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "books_per_year = pd.DataFrame(df_tem_clean['publication_date'].value_counts().reset_index().values, columns=[\"publication_date\",\"total_print_books\"])\n",
    "# books_per_year.sort_values(by=\"publication_date\", axis=1, ascending=True)\n",
    "books_per_year\n",
    "books_per_year.to_csv('Data/VizData/UoELibraryBooksPublishedPerYear.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Publication Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "396\n",
      "285\n",
      "396\n",
      "294\n",
      "394\n",
      "346\n",
      "7\n",
      "396\n",
      "359\n"
     ]
    }
   ],
   "source": [
    "# print(df0.publ_place.isnull().sum())\n",
    "# print(df0.publ_place1.isnull().sum())\n",
    "# print(df0.geographic_area_code.isnull().sum())\n",
    "# print(df0.geo_subdivision.isnull().sum())\n",
    "# print(df0.geo_subdivision1.isnull().sum())\n",
    "# print(df0.geo_subdivision2.isnull().sum())\n",
    "# print(df0.geo_name.isnull().sum())\n",
    "# print(df0.publisher.isnull().sum())\n",
    "# print(df0.publisher1.isnull().sum())\n",
    "# print(df0.text_language.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use 'publ_place' (as it has the fewest empty values in the test dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# publ_places = list(df0.publ_place)\n",
    "publ_places = df_geo.publ_place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_publ_places = []\n",
    "\n",
    "for p in publ_places:\n",
    "    p = str(p)\n",
    "    if p == 'nan':\n",
    "        clean_publ_places += [[]]\n",
    "    else:\n",
    "        if (p == \"Newcastle-Ont.-Tyne\"):  # manual fix for typo\n",
    "            p = \"Newcastle-on-Tyne\"\n",
    "        places = re.findall('[^\\W\\d]+[a-zA-Z\\-a-zA-Z]*[ öüèéí.]*[a-zA-Z\\-a-zA-Z]*[ ]*[^\\W\\d]+[.]*',p)  # chars to consider: áàåâæçéèîñöœûü\n",
    "        clean_places = []\n",
    "        for new_p in places:\n",
    "            clean = new_p.strip() # remove trailing whitespace\n",
    "            if len(clean) > 0:\n",
    "                clean_places += [clean]\n",
    "        clean_publ_places += [clean_places]\n",
    "\n",
    "assert len(publ_places) == len(clean_publ_places)\n",
    "# clean_publ_places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Lipsiae]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Edinburgi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[New York]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Basingstoke]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Basingstoke]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publication_place\n",
       "0         [Lipsiae]\n",
       "1       [Edinburgi]\n",
       "2        [New York]\n",
       "3     [Basingstoke]\n",
       "4     [Basingstoke]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df0_clean[\"publication_place\"] = clean_publ_places\n",
    "df_geo_clean = pd.DataFrame()\n",
    "df_geo_clean[\"publication_place\"] = clean_publ_places\n",
    "df_geo_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26711\n"
     ]
    }
   ],
   "source": [
    "all_publ_places = list(df_geo_clean['publication_place'])\n",
    "publ_place_counts = {(all_publ_places[0][0]):1}\n",
    "for place_list in all_publ_places:\n",
    "    for place in place_list:\n",
    "        if place in publ_place_counts:\n",
    "            publ_place_counts[place] += 1\n",
    "        else:\n",
    "            publ_place_counts[place] = 1\n",
    "print(len(publ_place_counts))\n",
    "\n",
    "\n",
    "# d = {}\n",
    "# d[1] = 1\n",
    "# if 2 in d:\n",
    "#     d[2] += 1\n",
    "# else:\n",
    "#     d[2] = 1\n",
    "# print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Publication Place</th>\n",
       "      <th>Total Books</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lipsiae</td>\n",
       "      <td>2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Edinburgi</td>\n",
       "      <td>4237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New York</td>\n",
       "      <td>83233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basingstoke</td>\n",
       "      <td>5289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boca Raton</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Publication Place  Total Books\n",
       "0           Lipsiae         2277\n",
       "1         Edinburgi         4237\n",
       "2          New York        83233\n",
       "3       Basingstoke         5289\n",
       "4        Boca Raton          516"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df0_clean\n",
    "df_geo_counts = pd.DataFrame()\n",
    "df_geo_counts['Publication Place'] = list(publ_place_counts.keys())\n",
    "df_geo_counts['Total Books'] = list(publ_place_counts.values())\n",
    "df_geo_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_geo_counts.to_csv('Data/VizData/books_per_publication_place.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Associated Data\n",
    "\n",
    "#### Subject Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(df0['loc_call_no'].isnull().sum())       # 159\n",
    "# print(df0['subject_cat_code'].isnull().sum())\n",
    "# print(df0['dewey_no'].isnull().sum())          # 304\n",
    "# print(df0['titles_words_assoc_w_name'].isnull().sum())\n",
    "# print(df0['general_subdivision'].isnull().sum())\n",
    "# print(df0['form_subdivision'].isnull().sum())\n",
    "# print(df0['general_subdivision1'].isnull().sum())\n",
    "# print(df0['topic_or_geo'].isnull().sum())      # 144\n",
    "# print(df0['general_subdivision2'].isnull().sum())\n",
    "# print(df0['general_subdivision3'].isnull().sum())\n",
    "# print(df0['genre_form_focus'].isnull().sum())\n",
    "# print(df0['genre_form_focus1'].isnull().sum())\n",
    "# print(df0['personal_name1'].isnull().sum())\n",
    "# print(df0['title1'].isnull().sum())\n",
    "# print()\n",
    "# print(df0['uniform_title1'].isnull().sum())\n",
    "# print()\n",
    "# print(df0['real_world_obj_URI2'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loc_call_nos = list(df0.loc_call_no)\n",
    "# topic_or_geo = list(df0.topic_or_geo)\n",
    "loc_call_nos = list(df_top.loc_call_no)\n",
    "topic_or_geo = list(df_top.topic_or_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PA3872',\n",
       " 'Unknown',\n",
       " 'HB119.F84',\n",
       " 'HB109.M63',\n",
       " 'HB103.K47',\n",
       " 'RG136',\n",
       " 'PA3443',\n",
       " 'Unknown',\n",
       " 'PA3872.Z4',\n",
       " 'HB501',\n",
       " 'HN13',\n",
       " 'Unknown',\n",
       " 'PA4035.N5',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'PL852.O8',\n",
       " 'PA4035.N5',\n",
       " 'JZ1480.A54',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'PN1978.J3',\n",
       " 'PL787.T3',\n",
       " 'KJC1083',\n",
       " 'PA3872.Z4',\n",
       " 'KJE947',\n",
       " 'DS835',\n",
       " 'DS894.59.A352',\n",
       " 'DS894.79.O372',\n",
       " 'DS894.39.F832',\n",
       " 'DS894.39.M592',\n",
       " 'DS894.79.H562',\n",
       " 'DS894.99.O365',\n",
       " 'PN1031',\n",
       " 'DS894.59.G532',\n",
       " 'DS896.38',\n",
       " 'KJC1854',\n",
       " 'DC430',\n",
       " 'DS894.69.K952',\n",
       " 'DS894.69.S452',\n",
       " 'DS895.G5',\n",
       " 'DC404',\n",
       " 'DS894.99.O365',\n",
       " 'Unknown',\n",
       " 'DS895.I77',\n",
       " 'DS855',\n",
       " 'Unknown',\n",
       " 'PR6045.I55',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'PL758.I5',\n",
       " 'PL758.I5',\n",
       " 'PL758.I5',\n",
       " 'PL758.I5',\n",
       " 'KJC1826',\n",
       " 'PL758.I5',\n",
       " 'PL758.I5',\n",
       " 'PL758.I5',\n",
       " 'Unknown',\n",
       " 'KJC1886',\n",
       " 'Unknown',\n",
       " 'PA3872.Z4',\n",
       " 'Unknown',\n",
       " 'PA4216',\n",
       " 'PA3082',\n",
       " 'PS163',\n",
       " 'PA3872.Z4',\n",
       " 'PA3061',\n",
       " 'Unknown',\n",
       " 'B765.A21',\n",
       " 'P306.8.A35',\n",
       " 'DP172',\n",
       " 'PA4253.O65',\n",
       " 'PA6766',\n",
       " 'PA4216',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'PA4216',\n",
       " 'AM41',\n",
       " 'Unknown',\n",
       " 'PS374.C5',\n",
       " 'PA3872.Z4',\n",
       " 'PR317.S82',\n",
       " 'PJ1981',\n",
       " 'Unknown',\n",
       " 'PA4216',\n",
       " 'Unknown',\n",
       " 'PJ1981',\n",
       " 'PR275.M3',\n",
       " 'Unknown',\n",
       " 'PA4218',\n",
       " 'HQ615',\n",
       " 'Unknown',\n",
       " 'PR6045.O53',\n",
       " 'PQ298',\n",
       " 'PA4216',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'HC240',\n",
       " 'Unknown',\n",
       " 'QH431',\n",
       " 'QP601',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'QP601',\n",
       " 'QP601',\n",
       " 'Unknown',\n",
       " 'QH431',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'QD75.2',\n",
       " 'QH426',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'QD291',\n",
       " 'QH426',\n",
       " 'QD411.5',\n",
       " 'Unknown',\n",
       " 'QK564',\n",
       " 'QH426',\n",
       " 'QH426',\n",
       " 'QH426',\n",
       " 'QH426',\n",
       " 'QH426',\n",
       " 'QH426',\n",
       " 'QH426',\n",
       " 'QH426',\n",
       " 'Unknown',\n",
       " 'QH426',\n",
       " 'Unknown',\n",
       " 'QH426',\n",
       " 'QC174.1',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'QD305.A2',\n",
       " 'QD96.N8',\n",
       " 'QE391.P84',\n",
       " 'QD902.5',\n",
       " 'Unknown',\n",
       " 'QD476',\n",
       " 'Unknown',\n",
       " 'QD411',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'QC100',\n",
       " 'Unknown',\n",
       " 'TL586',\n",
       " 'Unknown',\n",
       " 'QD461',\n",
       " 'TK7874',\n",
       " 'QA36',\n",
       " 'QB601',\n",
       " 'QA169',\n",
       " 'QA565',\n",
       " 'QA325',\n",
       " 'QA372',\n",
       " 'QB355',\n",
       " 'QR183.6',\n",
       " 'QR183.6',\n",
       " 'Unknown',\n",
       " 'QD291',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'NB90',\n",
       " 'TK7872.L3',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'HD209',\n",
       " 'Unknown',\n",
       " 'QD501',\n",
       " 'QK865',\n",
       " 'QD636',\n",
       " 'NK4649',\n",
       " 'Unknown',\n",
       " 'HM621',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'QD251',\n",
       " 'QD251',\n",
       " 'QC185',\n",
       " 'QD28',\n",
       " 'QD251',\n",
       " 'RT42',\n",
       " 'Unknown',\n",
       " 'QD251',\n",
       " 'QC454',\n",
       " 'QC454',\n",
       " 'QC454',\n",
       " 'QD258',\n",
       " 'N72.S6',\n",
       " 'QC61',\n",
       " 'QC61',\n",
       " 'PC3975.E5',\n",
       " 'K555',\n",
       " 'PR3694',\n",
       " 'PN5130.E8',\n",
       " 'PT4848.F6Z55x',\n",
       " 'QP251',\n",
       " 'DA506.A9',\n",
       " 'Q251',\n",
       " 'Unknown',\n",
       " 'PR4092',\n",
       " 'QP360',\n",
       " 'Unknown',\n",
       " 'PR2802.A25',\n",
       " 'QP90.5',\n",
       " 'TX553.F53',\n",
       " 'Unknown',\n",
       " 'PR3459.F3',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'KJV1290',\n",
       " 'HV6431',\n",
       " 'K4430',\n",
       " 'KJE5461',\n",
       " 'PT2607.U493',\n",
       " 'KJV1668',\n",
       " 'Unknown',\n",
       " 'KJV484',\n",
       " 'HV6025',\n",
       " 'PT2607.U493',\n",
       " 'PR1195.L37',\n",
       " 'Unknown',\n",
       " 'HD30.2',\n",
       " 'KJE6577',\n",
       " 'PN165',\n",
       " 'QP551',\n",
       " 'BF798',\n",
       " 'KJC9769.A37',\n",
       " 'PT2662.E75',\n",
       " 'Unknown',\n",
       " 'KJE982',\n",
       " 'Unknown',\n",
       " 'KD4210',\n",
       " 'QP84.6',\n",
       " 'PR1105',\n",
       " 'Unknown',\n",
       " 'QR184.3',\n",
       " 'PT2662.E7',\n",
       " 'KBR1320',\n",
       " 'UB800',\n",
       " 'PF3025',\n",
       " 'SF291',\n",
       " 'K1440',\n",
       " 'QH442.2',\n",
       " 'QP261',\n",
       " 'Unknown',\n",
       " 'QL761',\n",
       " 'QL738.5',\n",
       " 'PT2668.O35',\n",
       " 'Unknown',\n",
       " 'PT2668.O35',\n",
       " 'QP572.A54',\n",
       " 'Unknown',\n",
       " 'SF492',\n",
       " 'QP261',\n",
       " 'QP572.P74',\n",
       " 'QP572.S6',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'PT2611.E24',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'PJ7521',\n",
       " 'BS2745.52',\n",
       " 'Unknown',\n",
       " 'PT2603.E59',\n",
       " 'PT2611',\n",
       " 'QL677',\n",
       " 'Unknown',\n",
       " 'QK898.P8',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'BS2595.52',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'BS1122.H32',\n",
       " 'BS2617.5',\n",
       " 'PT4849.H4',\n",
       " 'BS2520.S8',\n",
       " 'Unknown',\n",
       " 'QH453',\n",
       " 'BV3160',\n",
       " 'HV6773',\n",
       " 'PT2639.S79',\n",
       " 'Unknown',\n",
       " 'K118.P82',\n",
       " 'HG930.5',\n",
       " 'HG930.5',\n",
       " 'HG2980.5.A6',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'HG3894',\n",
       " 'HG3894',\n",
       " 'HG1778.E/',\n",
       " 'HG2569',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'HG939.5',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'QA374.D84 1986',\n",
       " 'QK757',\n",
       " 'TA355',\n",
       " 'QA935',\n",
       " 'QE461.M23784 1989',\n",
       " 'QE1',\n",
       " 'QH541.5',\n",
       " 'QC661.J66 1985',\n",
       " 'QA614.86.V53 1989',\n",
       " 'QA280.D54 1989',\n",
       " 'QA275.D86 1989',\n",
       " 'Unknown',\n",
       " 'KDC313.L5',\n",
       " 'Unknown',\n",
       " 'HD2326',\n",
       " 'KF385',\n",
       " 'KF385',\n",
       " 'K230',\n",
       " 'KJA147',\n",
       " 'Unknown',\n",
       " 'KF425',\n",
       " 'Unknown',\n",
       " 'KD654',\n",
       " 'KD354',\n",
       " 'KF213',\n",
       " 'KDC186.C58',\n",
       " 'KD372.P35',\n",
       " 'KF224.S64',\n",
       " 'Unknown',\n",
       " 'DA822.F35',\n",
       " 'KD452.O94',\n",
       " 'K3820',\n",
       " 'K3943.A54',\n",
       " 'K3850.5',\n",
       " 'HF1455',\n",
       " 'HC60',\n",
       " 'K3830',\n",
       " 'K1413 1948',\n",
       " 'K1413 1967',\n",
       " 'K1447.4.A25',\n",
       " 'Unknown',\n",
       " 'K1447.3.A33',\n",
       " 'K3780.A41961',\n",
       " 'Unknown',\n",
       " 'K1500',\n",
       " 'Unknown',\n",
       " 'HJ1000',\n",
       " 'JC571',\n",
       " 'HF1713',\n",
       " 'Unknown',\n",
       " 'LAW',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'VM15',\n",
       " 'VM15',\n",
       " 'D21.3',\n",
       " 'TD883.1',\n",
       " 'QD25',\n",
       " 'BR141',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'PQ7082.P7',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'DA28.1 .W5',\n",
       " 'N6915',\n",
       " 'Unknown',\n",
       " 'PJ7529',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'DA787.A1 H83',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'JN5451',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'NA1050 .M297 1995',\n",
       " 'BP166.2',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'HM55 .C7',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'ND497.M85 S6',\n",
       " 'Unknown',\n",
       " 'QK495.A1',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'DG737.9 .R46',\n",
       " 'SD121',\n",
       " 'Unknown',\n",
       " 'QA331.7 .A52 1997',\n",
       " 'S590.4',\n",
       " 'Unknown',\n",
       " 'SD561',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'S589.7',\n",
       " 'QB801',\n",
       " 'GN320 .P44 1993',\n",
       " 'Unknown',\n",
       " 'HC130.E5',\n",
       " 'Unknown',\n",
       " 'DA68.12 .G74',\n",
       " 'BQ4398',\n",
       " 'Unknown',\n",
       " 'HC59.69',\n",
       " 'HC59.69',\n",
       " 'HC59.69',\n",
       " 'HC59.69',\n",
       " 'Unknown',\n",
       " 'HC59.69',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'RA643',\n",
       " 'Unknown',\n",
       " 'PN1994',\n",
       " 'DA566.4',\n",
       " 'Unknown',\n",
       " 'TK7881.6',\n",
       " 'Unknown',\n",
       " 'DS493.9.N94 W37 1996',\n",
       " 'PN1992.945',\n",
       " 'R835 .C37 1995',\n",
       " 'QL76 .N48 1996',\n",
       " 'PN1995.9.D6',\n",
       " 'D810.J4',\n",
       " 'DS570.Y83',\n",
       " 'E184.S2 S38 1994',\n",
       " 'DS489.25.M8 A73 1993',\n",
       " 'GT4814.A2 R57 1994',\n",
       " 'HN687',\n",
       " 'Unknown',\n",
       " 'GN347 .R55 1996',\n",
       " 'Unknown',\n",
       " 'HF1610 .U78 1996',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'GN635.S57',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'LB1060 .U53 1992',\n",
       " 'JF60',\n",
       " 'HC60 .B884 1997',\n",
       " 'HC433.5 .C65 1996',\n",
       " 'TP605',\n",
       " 'BS455',\n",
       " 'PR6064.A/',\n",
       " 'JK511',\n",
       " 'E443',\n",
       " 'DA88.1.D9',\n",
       " 'HV9069',\n",
       " 'P29',\n",
       " 'HD8390',\n",
       " 'JV185',\n",
       " 'K1965',\n",
       " 'RC514',\n",
       " 'QA141',\n",
       " 'RC263',\n",
       " 'HD9686.A2',\n",
       " 'DA963',\n",
       " 'D810.S7',\n",
       " 'HM36.5',\n",
       " 'HG8597',\n",
       " 'BC135',\n",
       " 'DD257.25',\n",
       " 'NA270',\n",
       " 'B778',\n",
       " 'HV1568',\n",
       " 'LB1025.2',\n",
       " 'DA4',\n",
       " 'PR4753',\n",
       " 'LF109',\n",
       " 'Unknown',\n",
       " 'CT1217.T6',\n",
       " 'HD9710.G74D4',\n",
       " 'DA69.3.M56',\n",
       " 'HV6025',\n",
       " 'LA721.81',\n",
       " 'TJ213',\n",
       " 'LB3051',\n",
       " 'PC2112',\n",
       " 'Unknown',\n",
       " 'HD8390',\n",
       " 'Unknown',\n",
       " 'PC1640',\n",
       " 'PC1640',\n",
       " 'Unknown',\n",
       " 'HV6248.M2797',\n",
       " 'DF631',\n",
       " 'DS473',\n",
       " 'CC81',\n",
       " 'KD1641',\n",
       " 'RJ499',\n",
       " 'TA685',\n",
       " 'JS3091',\n",
       " 'Unknown',\n",
       " 'HC241.25.G7',\n",
       " 'HC256.6',\n",
       " 'Unknown',\n",
       " 'HB615',\n",
       " 'HJ9423',\n",
       " 'HD9551.5',\n",
       " 'HD7096.G7',\n",
       " 'HV8959.R9',\n",
       " 'TG140.M3',\n",
       " 'NA680',\n",
       " 'Unknown',\n",
       " 'B809.8',\n",
       " 'Unknown',\n",
       " 'RC423',\n",
       " 'RA591.7',\n",
       " 'RA1242.T6',\n",
       " 'HV3008.G7',\n",
       " 'RA1151',\n",
       " 'HV249.S5',\n",
       " 'RC455.2.C65',\n",
       " 'RC346',\n",
       " 'RA1242.T6',\n",
       " 'QA374',\n",
       " 'QA371',\n",
       " 'T57.6',\n",
       " 'QA374',\n",
       " 'Unknown',\n",
       " 'TC405',\n",
       " 'TA645',\n",
       " 'QK711.2',\n",
       " 'QA247',\n",
       " 'QA372',\n",
       " 'Unknown',\n",
       " 'HD6502.A2',\n",
       " 'KD3040',\n",
       " 'T57.74',\n",
       " 'LB1025.2',\n",
       " 'JS3111',\n",
       " 'LB1025',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'BX1530',\n",
       " 'PA8260',\n",
       " 'BX2470',\n",
       " 'BV1515',\n",
       " 'HS2865.L/O/',\n",
       " 'Unknown',\n",
       " 'DS36.8',\n",
       " 'PT2433.M4',\n",
       " 'Unknown',\n",
       " 'PT7063',\n",
       " 'PT9876.15K77',\n",
       " 'Unknown',\n",
       " 'PT8363',\n",
       " 'PT9876.15.K77',\n",
       " 'Z7770',\n",
       " 'PT9876.15.K77',\n",
       " 'Unknown',\n",
       " 'PT9876.15.K77',\n",
       " 'PQ1522',\n",
       " 'Unknown',\n",
       " 'PQ1424.A4',\n",
       " 'Unknown',\n",
       " 'PT9876.15.V3',\n",
       " 'Z7770',\n",
       " 'PQ2474',\n",
       " 'PT9876.15.V3',\n",
       " 'PT9876.15.K7',\n",
       " 'PQ2474.Z5',\n",
       " 'PQ1183',\n",
       " 'PQ2344.Z5',\n",
       " 'BS425',\n",
       " 'PQ2463',\n",
       " 'BS425',\n",
       " 'PT9876.15.K55',\n",
       " 'Unknown',\n",
       " 'PT9876.15.K55',\n",
       " 'BS440',\n",
       " 'PT9876.15.K55',\n",
       " 'BS440',\n",
       " 'PQ2387.R5',\n",
       " 'PT9876.15.V3',\n",
       " 'PQ2387',\n",
       " 'PQ2387.R5',\n",
       " 'PT9875.F788',\n",
       " 'PQ2601.R2',\n",
       " 'Unknown',\n",
       " 'PN203',\n",
       " 'PQ2603.R35',\n",
       " 'PQ2603.R35',\n",
       " 'PQ2607.E75',\n",
       " 'PT9876.16.A45',\n",
       " 'PQ2611.R437',\n",
       " 'PQ2625.I2',\n",
       " 'BS440',\n",
       " 'PQ2635.E85',\n",
       " 'Unknown',\n",
       " 'PQ1573',\n",
       " 'Unknown',\n",
       " 'PQ1956.A73',\n",
       " 'PT9876.16.A45',\n",
       " 'PR6003.E282',\n",
       " 'PQ2613.E53',\n",
       " 'Z6371.D4',\n",
       " 'PQ2617.O6',\n",
       " 'PQ1567',\n",
       " 'Unknown',\n",
       " 'PQ631',\n",
       " 'PQ2043',\n",
       " 'BS195 .J4 1968',\n",
       " 'Z7771.A5',\n",
       " 'BS230',\n",
       " 'BS447.W3',\n",
       " 'PQ2205',\n",
       " 'DG78',\n",
       " 'N7790',\n",
       " 'Unknown',\n",
       " 'PQ2205.Z5',\n",
       " 'PQ2441',\n",
       " 'PQ2260.G36',\n",
       " 'Q175.5',\n",
       " 'PQ2260.G36',\n",
       " 'QA29.N4',\n",
       " 'QA28',\n",
       " 'Unknown',\n",
       " 'QA155',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'PQ2362.Z5',\n",
       " 'PQ2625.I16',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'DD801.S352',\n",
       " 'Unknown',\n",
       " 'GN281',\n",
       " 'GN803',\n",
       " 'DL121 .B7',\n",
       " 'PQ2152.A5',\n",
       " 'Unknown',\n",
       " 'PQ2528',\n",
       " 'PQ2511.O42',\n",
       " 'PQ2534',\n",
       " 'PQ2605.A3734',\n",
       " 'PN1997.L13',\n",
       " 'PQ2678.I47',\n",
       " 'PQ2635.O5',\n",
       " 'PQ2635.O5',\n",
       " 'PQ2635.O5',\n",
       " 'PR403',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'PR5451',\n",
       " 'BV4010',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'BV4011',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'BV4360',\n",
       " 'BV660.2',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'BV4011',\n",
       " 'BV675.5',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'G850 1902',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'BV2653',\n",
       " 'BV4011',\n",
       " 'Unknown',\n",
       " 'BV660.2',\n",
       " 'BV675',\n",
       " 'BV660.2',\n",
       " 'BV4320',\n",
       " 'BV4012.2',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'BX1970',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'RA971.3',\n",
       " 'RA972.5',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'RA1231.P55',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'HD7269.A6',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'K286',\n",
       " 'Unknown',\n",
       " 'KK938',\n",
       " 'Unknown',\n",
       " 'HD7269.A6',\n",
       " 'K242',\n",
       " 'KF352',\n",
       " 'HD7269.A6',\n",
       " 'HD7269.A6',\n",
       " 'K334',\n",
       " 'HD7269.A6',\n",
       " 'HD7269.A6',\n",
       " 'K250',\n",
       " 'Unknown',\n",
       " 'KNN132',\n",
       " 'K160',\n",
       " 'K230.S645',\n",
       " 'HD9698.5',\n",
       " 'Unknown',\n",
       " 'K230.S736',\n",
       " 'Unknown',\n",
       " 'K230.S736',\n",
       " 'K372',\n",
       " 'Unknown',\n",
       " 'K415',\n",
       " 'K212',\n",
       " 'K574',\n",
       " 'K230.S76',\n",
       " 'K371',\n",
       " 'K357',\n",
       " 'Unknown',\n",
       " 'RA975',\n",
       " 'K215.E53',\n",
       " 'Unknown',\n",
       " 'JA71',\n",
       " 'Unknown',\n",
       " 'K415',\n",
       " 'Unknown',\n",
       " 'JC223.M66',\n",
       " 'K235',\n",
       " 'Unknown',\n",
       " 'K252',\n",
       " 'K230.U56',\n",
       " 'JA71',\n",
       " 'K460',\n",
       " 'K230.D437',\n",
       " 'K230.D437',\n",
       " 'B65',\n",
       " 'K230.V52',\n",
       " 'K215.F74',\n",
       " 'JA66',\n",
       " 'K235',\n",
       " 'QA297',\n",
       " 'N66',\n",
       " 'RD592.9.C87',\n",
       " 'Z6620.F8',\n",
       " 'HB180.J3',\n",
       " 'HC462.9',\n",
       " 'AI19.J3',\n",
       " 'HC59',\n",
       " 'HC79.T4',\n",
       " 'HC465.S3',\n",
       " 'HQ1743',\n",
       " 'TA345',\n",
       " 'Unknown',\n",
       " 'HC462.9',\n",
       " 'Unknown',\n",
       " 'TA345',\n",
       " 'HC462',\n",
       " 'F1465.2.M3',\n",
       " 'AI19.J3',\n",
       " 'HB135',\n",
       " 'N350',\n",
       " 'E98.F39',\n",
       " 'AI19.J3',\n",
       " 'HB72',\n",
       " 'BQ676',\n",
       " 'Unknown',\n",
       " 'Z6621.B193',\n",
       " 'QA273',\n",
       " 'F849.L35',\n",
       " 'QA76.7',\n",
       " 'BQ8552',\n",
       " 'Q185',\n",
       " 'F392.F7',\n",
       " 'HD70.J3',\n",
       " 'HD70.J3',\n",
       " 'PA3024',\n",
       " 'Unknown',\n",
       " 'CD1689.S77',\n",
       " 'AE35.2',\n",
       " 'HD70.J3',\n",
       " 'U27',\n",
       " 'HD8726.8',\n",
       " 'QA297',\n",
       " 'DU122.J36',\n",
       " 'Unknown',\n",
       " 'Z6623',\n",
       " 'QA76.73.J38 L52 2007',\n",
       " 'QA276.4',\n",
       " 'Unknown',\n",
       " 'DC33.7',\n",
       " 'AE35.2',\n",
       " 'N365.G7',\n",
       " 'BF458',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'GV854',\n",
       " 'DS479',\n",
       " 'Q335',\n",
       " 'Z6621.L82',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Z6621.L82',\n",
       " 'Unknown',\n",
       " 'PA4240.L4',\n",
       " 'Unknown',\n",
       " 'Z6621.L82',\n",
       " 'Z6621.B844',\n",
       " 'HF5387',\n",
       " 'Unknown',\n",
       " 'HD70.J3',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'HF1359',\n",
       " 'HG4028.C6',\n",
       " 'HF5500.3.J3',\n",
       " 'Unknown',\n",
       " 'HD37.J3',\n",
       " 'Unknown',\n",
       " 'DS911.2',\n",
       " 'HG3977',\n",
       " 'HD62.4',\n",
       " 'HF5548.37',\n",
       " 'S613',\n",
       " 'HC462.9',\n",
       " 'BF531',\n",
       " 'KF4783',\n",
       " 'Unknown',\n",
       " 'KLB820.3',\n",
       " 'RC454',\n",
       " 'Unknown',\n",
       " 'KK2249.2',\n",
       " 'RA407.5.E85',\n",
       " 'PG3492.76.I53',\n",
       " 'Unknown',\n",
       " 'RC569.5.A34',\n",
       " 'QE711.2',\n",
       " 'PL642',\n",
       " 'N6763',\n",
       " 'QB631',\n",
       " 'PG2112',\n",
       " 'NX663.I8',\n",
       " 'RC455.2.E94',\n",
       " 'N7337',\n",
       " 'Unknown',\n",
       " 'PQ4683.B43',\n",
       " 'HV697',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'GV1204.55',\n",
       " 'PG3485.7.U225',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'PN6519.J3',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'JZ1305',\n",
       " 'RC514',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'BF575.A5',\n",
       " 'BF637.C45',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'BF441',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'BF385',\n",
       " 'RC554',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'PT1176',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'PT641',\n",
       " 'Unknown',\n",
       " 'PN2658.G7',\n",
       " 'Unknown',\n",
       " 'AG55',\n",
       " 'Unknown',\n",
       " 'PT343',\n",
       " 'PN689',\n",
       " 'RC512',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'GR166',\n",
       " 'Unknown',\n",
       " 'RJ216',\n",
       " 'PT1160.E8',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'BX9223',\n",
       " 'Unknown',\n",
       " 'DS778.7',\n",
       " 'Unknown',\n",
       " 'BX9223',\n",
       " 'HG221',\n",
       " 'PT85',\n",
       " 'RC451.4.A5',\n",
       " 'PT155',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'PT85',\n",
       " 'HN800.N5',\n",
       " 'JK518',\n",
       " 'E744',\n",
       " 'JZ1305',\n",
       " 'LAW',\n",
       " 'KD4080',\n",
       " 'JZ1305',\n",
       " 'DD86.8',\n",
       " 'JN237.1967',\n",
       " 'JK723.E9',\n",
       " 'JN673',\n",
       " 'JN6598.K7',\n",
       " 'JA37',\n",
       " 'JF1351',\n",
       " 'JA81',\n",
       " 'KD4890',\n",
       " 'HN440.E4',\n",
       " 'HX239.Z7',\n",
       " 'JS4947',\n",
       " 'HX288',\n",
       " 'HM261',\n",
       " 'E178',\n",
       " 'HD4145',\n",
       " 'DC404',\n",
       " 'HD4145',\n",
       " 'DK274',\n",
       " 'JK274',\n",
       " 'DK267',\n",
       " 'JK1061',\n",
       " 'PN4748.G7',\n",
       " 'HV8699.G8',\n",
       " 'JZ5600',\n",
       " 'HN400.E4',\n",
       " 'DS777.55',\n",
       " ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_call_nos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the LCC main class of a record (in this case, a printed book) from the Library of Congress Call Number\n",
    "\n",
    "*Based on the Library of Congress Classification (LCC) Outline: https://www.loc.gov/catdir/cpso/lcco/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1297311\n"
     ]
    }
   ],
   "source": [
    "lcc_dict = {'A':'GENERAL WORKS','B':'PHILOSOPHY. PSYCHOLOGY. RELIGION','C':'AUXILIARY SCIENCES OF HISTORY',\n",
    "            'D':'WORLD HISTORY AND HISTORY OF EUROPE, ASIA, AFRICA, AUSTRALIA, NEW ZEALAND, ETC.',\n",
    "            'E':'HISTORY OF THE AMERICAS','F':'HISTORY OF THE AMERICAS','G':'GEOGRAPHY. ANTHROPOLOGY. RECREATION',\n",
    "            'H':'SOCIAL SCIENCES','J':'POLITICAL SCIENCE','K':'LAW','L':'EDUCATION','M':'MUSIC AND BOOKS ON MUSIC',\n",
    "            'N':'FINE ARTS','P':'LANGUAGE AND LITERATURE','Q':'SCIENCE','R':'MEDICINE','S':'AGRICULTURE',\n",
    "            'T':'TECHNOLOGY','U':'MILITARY SCIENCE','V':'NAVAL SCIENCE','Z':'BIBLIOGRAPHY. LIBRARY SCIENCE. INFORMATION RESOURCES (GENERAL)'}\n",
    "\n",
    "lcc_main_class_letters = lcc_dict.keys()\n",
    "\n",
    "def validLCC(call_number, lcc_main_class_letters):\n",
    "    first_char = str(call_number)[0]\n",
    "    if first_char in lcc_main_class_letters:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "lcc_main_class_list = []\n",
    "for call_no in loc_call_nos:\n",
    "    call_no = str(call_no)\n",
    "    if (call_no == 'nan') or (not validLCC(call_no, lcc_main_class_letters)):\n",
    "        lcc_main_class_list += [\"UNKNOWN\"]\n",
    "    else:\n",
    "        first_letter = call_no[0]\n",
    "        main_class = lcc_dict[first_letter]\n",
    "        lcc_main_class_list += [main_class]\n",
    "        \n",
    "assert len(lcc_main_class_list) == len(loc_call_nos)\n",
    "print(len(lcc_main_class_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcc_no</th>\n",
       "      <th>lcc_main_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1297306</th>\n",
       "      <td>PT2621.A26</td>\n",
       "      <td>LANGUAGE AND LITERATURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297307</th>\n",
       "      <td>NB623.B5</td>\n",
       "      <td>FINE ARTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297308</th>\n",
       "      <td>HF3756.5</td>\n",
       "      <td>SOCIAL SCIENCES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297309</th>\n",
       "      <td>P81.G7</td>\n",
       "      <td>LANGUAGE AND LITERATURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297310</th>\n",
       "      <td>HD47.4</td>\n",
       "      <td>SOCIAL SCIENCES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             lcc_no           lcc_main_class\n",
       "1297306  PT2621.A26  LANGUAGE AND LITERATURE\n",
       "1297307    NB623.B5                FINE ARTS\n",
       "1297308    HF3756.5          SOCIAL SCIENCES\n",
       "1297309      P81.G7  LANGUAGE AND LITERATURE\n",
       "1297310      HD47.4          SOCIAL SCIENCES"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df0_clean['lcc_no'] = loc_call_nos\n",
    "# df0_clean['lcc_main_class'] = lcc_main_class_list\n",
    "#df0_clean\n",
    "df_top_clean = pd.DataFrame()\n",
    "df_top_clean['lcc_no'] = loc_call_nos\n",
    "df_top_clean['lcc_main_class'] = lcc_main_class_list\n",
    "df_top_clean.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68348\n"
     ]
    }
   ],
   "source": [
    "print(len(pd.unique(topic_or_geo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_topic_or_geo = []\n",
    "for terms in topic_or_geo:\n",
    "    terms = str(terms)\n",
    "    if terms == 'nan':\n",
    "        new_terms = []\n",
    "    else:\n",
    "        terms = terms.replace('.','')\n",
    "        new_terms = list(set(terms.split(';')))  # set is list of unique elements (no duplicates)\n",
    "    new_topic_or_geo += [new_terms]\n",
    "\n",
    "assert len(new_topic_or_geo) == len(topic_or_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new_topic_or_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcc_no</th>\n",
       "      <th>lcc_main_class</th>\n",
       "      <th>ddc_no</th>\n",
       "      <th>ddc_main_class</th>\n",
       "      <th>topic_or_geo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PA3872</td>\n",
       "      <td>LANGUAGE AND LITERATURE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>[Argonauts (Greek mythology)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>MILITARY SCIENCE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>[Hepatitis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HB119.F84</td>\n",
       "      <td>SOCIAL SCIENCES</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>[Economists]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HB109.M63</td>\n",
       "      <td>SOCIAL SCIENCES</td>\n",
       "      <td>B</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>[Keynesian economics]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HB103.K47</td>\n",
       "      <td>SOCIAL SCIENCES</td>\n",
       "      <td>330.156</td>\n",
       "      <td>Social sciences</td>\n",
       "      <td>[Economists]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lcc_no           lcc_main_class   ddc_no   ddc_main_class  \\\n",
       "0     PA3872  LANGUAGE AND LITERATURE  Unknown          Unknown   \n",
       "1    Unknown         MILITARY SCIENCE  Unknown          Unknown   \n",
       "2  HB119.F84          SOCIAL SCIENCES  Unknown          Unknown   \n",
       "3  HB109.M63          SOCIAL SCIENCES        B          Unknown   \n",
       "4  HB103.K47          SOCIAL SCIENCES  330.156  Social sciences   \n",
       "\n",
       "                    topic_or_geo  \n",
       "0  [Argonauts (Greek mythology)]  \n",
       "1                    [Hepatitis]  \n",
       "2                   [Economists]  \n",
       "3          [Keynesian economics]  \n",
       "4                   [Economists]  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df0_clean['topic_or_geo'] = new_topic_or_geo\n",
    "#df0_clean\n",
    "\n",
    "# df_geo_clean['topic_or_geo'] = new_topic_or_geo\n",
    "# df_geo_clean.head()\n",
    "\n",
    "df_top_clean['topic_or_geo'] = new_topic_or_geo\n",
    "df_top_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the DDC main class of a record (in this case, a printed book) from the Dewey Decimal Classification number\n",
    "\n",
    "*Based on the DDC23 summaries: https://www.oclc.org/content/dam/oclc/dewey/ddc23-summaries.pdf*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Technology',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Arts & recreation',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Literature',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Language',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Computer science, information & general works',\n",
       " 'Unknown',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'History & geography',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Technology',\n",
       " 'Science',\n",
       " 'Science',\n",
       " 'Science',\n",
       " 'Science',\n",
       " 'Science',\n",
       " 'Science',\n",
       " 'Unknown',\n",
       " 'Science',\n",
       " 'Science',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Literature',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Computer science, information & general works',\n",
       " 'Unknown',\n",
       " 'Science',\n",
       " 'Unknown',\n",
       " 'Science',\n",
       " 'Science',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Literature',\n",
       " 'Technology',\n",
       " 'Technology',\n",
       " 'Technology',\n",
       " 'Literature',\n",
       " 'Technology',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Technology',\n",
       " 'Social sciences',\n",
       " 'Literature',\n",
       " 'Science',\n",
       " 'Philosophy & psychology',\n",
       " 'Unknown',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Technology',\n",
       " 'Literature',\n",
       " 'Religion',\n",
       " 'Social sciences',\n",
       " 'Literature',\n",
       " 'Technology',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Science',\n",
       " 'Unknown',\n",
       " 'Science',\n",
       " 'Science',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Technology',\n",
       " 'Unknown',\n",
       " 'Technology',\n",
       " 'Science',\n",
       " 'Technology',\n",
       " 'Technology',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Literature',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Science',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Religion',\n",
       " 'Science',\n",
       " 'Science',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Technology',\n",
       " 'Science',\n",
       " 'Science',\n",
       " 'Technology',\n",
       " 'Science',\n",
       " 'Unknown',\n",
       " 'Science',\n",
       " 'Unknown',\n",
       " 'Science',\n",
       " 'Science',\n",
       " 'Science',\n",
       " 'Science',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Technology',\n",
       " 'Technology',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Arts & recreation',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Technology',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Language',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Arts & recreation',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Technology',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'History & geography',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'History & geography',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Technology',\n",
       " 'Religion',\n",
       " 'Literature',\n",
       " 'Social sciences',\n",
       " 'History & geography',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Language',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Technology',\n",
       " 'Science',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'History & geography',\n",
       " 'History & geography',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Science',\n",
       " 'History & geography',\n",
       " 'Arts & recreation',\n",
       " 'Philosophy & psychology',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Literature',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'History & geography',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Technology',\n",
       " 'Social sciences',\n",
       " 'Language',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Language',\n",
       " 'Language',\n",
       " 'Language',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'History & geography',\n",
       " 'History & geography',\n",
       " 'History & geography',\n",
       " 'Technology',\n",
       " 'Technology',\n",
       " 'Technology',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Arts & recreation',\n",
       " 'Arts & recreation',\n",
       " 'Philosophy & psychology',\n",
       " 'Social sciences',\n",
       " 'Technology',\n",
       " 'Technology',\n",
       " 'Technology',\n",
       " 'Social sciences',\n",
       " 'Technology',\n",
       " 'Social sciences',\n",
       " 'Technology',\n",
       " 'Technology',\n",
       " 'Technology',\n",
       " 'Science',\n",
       " 'Science',\n",
       " 'Technology',\n",
       " 'Science',\n",
       " 'Unknown',\n",
       " 'Technology',\n",
       " 'Technology',\n",
       " 'Science',\n",
       " 'Science',\n",
       " 'Science',\n",
       " 'Science',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Science',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Science',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Religion',\n",
       " 'Religion',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Literature',\n",
       " 'History & geography',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Computer science, information & general works',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Literature',\n",
       " 'Computer science, information & general works',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'History & geography',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Religion',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Religion',\n",
       " 'Literature',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Computer science, information & general works',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Religion',\n",
       " 'Computer science, information & general works',\n",
       " 'Computer science, information & general works',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'History & geography',\n",
       " 'History & geography',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'History & geography',\n",
       " 'Unknown',\n",
       " 'Science',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Literature',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Religion',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Religion',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Religion',\n",
       " 'Religion',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Religion',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Religion',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Religion',\n",
       " 'Religion',\n",
       " 'Religion',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Religion',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Technology',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Technology',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Technology',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Technology',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Technology',\n",
       " 'Philosophy & psychology',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Philosophy & psychology',\n",
       " 'Social sciences',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Science',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Technology',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Computer science, information & general works',\n",
       " 'Unknown',\n",
       " 'Science',\n",
       " 'Unknown',\n",
       " 'Technology',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Technology',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Arts & recreation',\n",
       " 'Unknown',\n",
       " 'Computer science, information & general works',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Computer science, information & general works',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Computer science, information & general works',\n",
       " 'Computer science, information & general works',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Philosophy & psychology',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Technology',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Technology',\n",
       " 'Science',\n",
       " 'Unknown',\n",
       " 'Arts & recreation',\n",
       " 'Science',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Technology',\n",
       " 'Arts & recreation',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Arts & recreation',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Technology',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Philosophy & psychology',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Philosophy & psychology',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Technology',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Arts & recreation',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Literature',\n",
       " 'Technology',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Technology',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'History & geography',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Technology',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Literature',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Social sciences',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " 'Unknown',\n",
       " ...]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dewey_nos = list(df_top.dewey_no)\n",
    "\n",
    "# INPUT: Dewey Decimal Classification number (string)\n",
    "# OUTPUT: Dewey Decimal Classification main class name (string)\n",
    "def DdcClassName(ddc_number):\n",
    "\n",
    "    ddc_dict = {'000':'Computer science, information & general works',\n",
    "            '100':'Philosophy & psychology','200':'Religion','300':'Social sciences',\n",
    "            '400':'Language','500':'Science','600':'Technology','700':'Arts & recreation',\n",
    "            '800':'Literature','900':'History & geography'}\n",
    "    \n",
    "    if str(ddc_number) == 'nan':\n",
    "        return \"Unknown\"\n",
    "    else:\n",
    "        digits = re.findall('\\d{1}',ddc_number)\n",
    "        if (len(digits) > 0):\n",
    "            first_digit = digits[0]\n",
    "            main_class_no = first_digit + '00'\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "        return ddc_dict[main_class_no]\n",
    "\n",
    "\n",
    "ddc_main_class_list = []\n",
    "for call_no in dewey_nos:\n",
    "    ddc_main_class_list += [DdcClassName(str(call_no))]\n",
    "        \n",
    "assert len(ddc_main_class_list) == len(dewey_nos)\n",
    "ddc_main_class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcc_no</th>\n",
       "      <th>lcc_main_class</th>\n",
       "      <th>ddc_no</th>\n",
       "      <th>ddc_main_class</th>\n",
       "      <th>topic_or_geo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PA3872</td>\n",
       "      <td>LANGUAGE AND LITERATURE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>[Argonauts (Greek mythology)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>MILITARY SCIENCE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>[Hepatitis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HB119.F84</td>\n",
       "      <td>SOCIAL SCIENCES</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>[Economists]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HB109.M63</td>\n",
       "      <td>SOCIAL SCIENCES</td>\n",
       "      <td>B</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>[Keynesian economics]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HB103.K47</td>\n",
       "      <td>SOCIAL SCIENCES</td>\n",
       "      <td>330.156</td>\n",
       "      <td>Social sciences</td>\n",
       "      <td>[Economists]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lcc_no           lcc_main_class   ddc_no   ddc_main_class  \\\n",
       "0     PA3872  LANGUAGE AND LITERATURE  Unknown          Unknown   \n",
       "1    Unknown         MILITARY SCIENCE  Unknown          Unknown   \n",
       "2  HB119.F84          SOCIAL SCIENCES  Unknown          Unknown   \n",
       "3  HB109.M63          SOCIAL SCIENCES        B          Unknown   \n",
       "4  HB103.K47          SOCIAL SCIENCES  330.156  Social sciences   \n",
       "\n",
       "                    topic_or_geo  \n",
       "0  [Argonauts (Greek mythology)]  \n",
       "1                    [Hepatitis]  \n",
       "2                   [Economists]  \n",
       "3          [Keynesian economics]  \n",
       "4                   [Economists]  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df0_clean['ddc_no'] = dewey_nos\n",
    "# df0_clean['ddc_main_class'] = ddc_main_class_list\n",
    "# df0_clean\n",
    "\n",
    "df_top_clean['ddc_no'] = dewey_nos\n",
    "df_top_clean['ddc_main_class'] = ddc_main_class_list\n",
    "\n",
    "df_top_clean\n",
    "\n",
    "df_top_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export a CSV of the cleaned topical dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_top_clean.to_csv('Data/VizData/topical_print_book_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine how many records have no subject classification information (meaning no topical term nor geographic name, no Library of Congress call number, and no Dewey Decimal call number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_subjects = []\n",
    "for index,row in df0_clean.iterrows():\n",
    "    if (len(row['topic_or_geo']) == 0) and (row['lcc_main_class'] == \"UNKNOWN\") and (row['ddc_main_class'] == \"Unknown\"):\n",
    "        no_subjects.append(index)\n",
    "\n",
    "print(len(no_subjects),\"records do not have subject information:\")\n",
    "print(no_subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Publication Place: Countries and Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            features               type\n",
      "0  {'type': 'Feature', 'geometry': {'type': 'Poin...  FeatureCollection\n",
      "1  {'type': 'Feature', 'geometry': {'type': 'Poin...  FeatureCollection\n",
      "2  {'type': 'Feature', 'geometry': {'type': 'Poin...  FeatureCollection\n",
      "3  {'type': 'Feature', 'geometry': {'type': 'Poin...  FeatureCollection\n",
      "4  {'type': 'Feature', 'geometry': {'type': 'Poin...  FeatureCollection\n",
      "(1249, 2)\n"
     ]
    }
   ],
   "source": [
    "cities_countries = pd.read_json(\"Data/MapData/ne_50m_populated_places/ne_50m_populated_places.json\",typ='frame')\n",
    "print(cities_countries.head())\n",
    "print(cities_countries.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: Bombo\n",
      "Country: Uganda\n",
      "Coordinates: [32.533299524864844, 0.583299105614628]\n"
     ]
    }
   ],
   "source": [
    "print(\"City:\", cities_countries.iloc[0].features['properties']['NAME'])             # NAME = city name\n",
    "print(\"Country:\", cities_countries.iloc[0].features['properties']['ADM0NAME'])      # SOV0NAME = country name\n",
    "print(\"Coordinates:\", cities_countries.iloc[0].features['geometry']['coordinates'])  # coordinates = latitude,longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Create CSV files of cities, their countries and their coordinates, and the number of records published in that city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First create one list each for worldwide cities, worldwide countries, and worldwide city coordinates, and\n",
    "# a list of cities per country contained in a list of all countries worldwide\n",
    "\n",
    "cities_list = []\n",
    "countries_list = []\n",
    "cities_per_country = []\n",
    "city_coords_list = []\n",
    "maxI = cities_countries.shape[0]\n",
    "i = 0\n",
    "country = cities_countries.iloc[0].features['properties']['ADM0NAME']\n",
    "country_cities = []\n",
    "while i < maxI:\n",
    "    new_country = cities_countries.iloc[i].features['properties']['ADM0NAME']\n",
    "    new_city = cities_countries.iloc[i].features['properties']['NAME']\n",
    "    \n",
    "    # Create a list of cities per country\n",
    "    if country == new_country:\n",
    "        country_cities.append(new_city)\n",
    "    else:\n",
    "        cities_per_country.append([country,country_cities])\n",
    "        # Create a list of unique countries (non-repeating)\n",
    "        countries_list.append(country)\n",
    "        country = new_country\n",
    "    \n",
    "    # Create a list of unique cities (non-repeating)\n",
    "    cities_list.append(new_city)\n",
    "    # Create a list of unique coordinates for each city (non-repeating)\n",
    "    city_coords_list.append(cities_countries.iloc[i].features['geometry']['coordinates'])\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "assert len(city_coords_list) == len(cities_list)\n",
    "\n",
    "# print(cities_per_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Second create a list of the total number of books (a.k.a. records or dataframe rows) published in each city\n",
    "\n",
    "publ_cities = []\n",
    "publ_cities_lists = df0_clean['publication_place']\n",
    "for cities in publ_cities_lists:\n",
    "    for city in cities:\n",
    "        if '.' not in city:       # states are abbreviated with periods (.)\n",
    "            publ_cities.append(city)\n",
    "\n",
    "#publ_cities  # Note that some items in this list are actually countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# countries_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# INPUT: [first] a list of cities worldwide (strings) and [second] a list of cities to count\n",
    "# OUTPUT: list of the total times each city from the second list appears for every city in the first list\n",
    "def countCities(world_cities,to_count):\n",
    "    city_counts = []\n",
    "    for world_city in world_cities:\n",
    "        count = 0\n",
    "        for city in to_count:\n",
    "            if world_city in city:\n",
    "                count += 1\n",
    "        city_counts.append(count)\n",
    "    \n",
    "    return city_counts\n",
    "\n",
    "city_totals = countCities(cities_list,publ_cities)\n",
    "assert len(city_totals) == len(cities_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Third create a list of the total number of books (a.k.a. records or dataframe rows) published in each country\n",
    "\n",
    "# INPUT: [first] a list of countries worldwide (strings) and their corresponding cities (lists of strings) \n",
    "#        and [second] a list of cities to count\n",
    "# OUTPUT: list of the total times each city from the second list appears for every city in the first list\n",
    "def countCountriesByCity(world_cities_per_country,to_count):\n",
    "    country_totals = []\n",
    "    for world_country in world_cities_per_country:\n",
    "        count = 0\n",
    "        country = world_country[0]\n",
    "        cities = world_country[0]\n",
    "        for city in to_count:\n",
    "            if city in cities:\n",
    "                count += 1\n",
    "        country_totals.append(count)\n",
    "    \n",
    "    return country_totals\n",
    "\n",
    "country_totals = countCountriesByCity(cities_per_country,publ_cities)\n",
    "assert len(country_totals) == len(countries_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
